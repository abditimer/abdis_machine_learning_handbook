{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37164bitdatascienceenvvenvc7e335f45fcf4ed5bb97715a7b64d407",
   "display_name": "Python 3.7.1 64-bit ('datascienceenv': venv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Basics of Deep Learning\n",
    "In this notebook, we will cover the basics behind Deep Learning. I'm talking about building a brain....\n",
    "\n",
    "![gif of some colours](https://www.fleetscience.org/sites/default/files/images/neural-mlblog.gif)\n",
    "\n",
    "Only kidding. Deep learning is a fascinating new field that has exploded over the last few years. From being used as facial recognition in apps such as SnapChat or challenger banks, to more advanced use cases such as being used in [protein-folding](https://www.independent.co.uk/life-style/gadgets-and-tech/protein-folding-ai-deepmind-google-cancer-covid-b1764008.html).\n",
    "\n",
    "In this notebook we will:\n",
    "- Explain the building blocks of neural networks\n",
    "- Go over some applications of Deep Learning"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Building blocks of Neural Networks\n",
    "\n",
    "I have no doubt that you have heard/seen how similar neural networks are to....our brains. \n",
    "\n",
    "\n",
    "### The Perceptron\n",
    "\n",
    "The building block of neural networks. The perceptron has a rich history (covered in the background section of this book). The perceptron was created in 1958 by Frank Rosenblatt (I love that name) in Cornell, however, that story is for another day....or section in this book (backgrounds!),\n",
    "\n",
    "The perceptron is an algorithm that can learn a binary classifier (e.g. is that a cat or dog?). This is known as a threshold function, which maps an input vector *x* to an output decision *$f(x)$ = output*. Here is the formal maths to better explain my verbal fluff:\n",
    "\n",
    "$ f(x) = { 1 (if: w.x+b > 0), 0 (otherwise) $\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "5+5"
   ]
  }
 ]
}